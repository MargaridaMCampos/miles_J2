{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Love Thy Neighbour\n",
    "\n",
    "In this Mission you'll learn all about distances between data points and how we can take insights from each point's neighbours. You will also learn two new models:\n",
    "\n",
    " - KNN for Classification\n",
    " - K-Means for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "The provided dataset contains information about **penguins**:\n",
    " - `species`: (string) the penguin's species\n",
    " - `island`: (string) the penguin's origin island\n",
    " - `culmen_length_mm`: (number) culmen's length in milimiters \n",
    " - `culmen_depth_mm`: (number) culmen's depth in milimiters \n",
    " - `flipper_length_mm`: (number) flipper's length in milimiters\n",
    " - `body_mass_g`: (number) penguin's mass in grams\n",
    " - `is_male`: (integer) whether the penguin is male (1) or female (0)\n",
    " \n",
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('penguins_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Always start by taking a look at the dataset, getting familair with the variables and check any data issues, before diving into the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Let's get different distances between all our points.\n",
    "#### 1.1 Create a new dataframe with only the numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Create a new dataframe, called `all_comb` with all the combinations of pairs of points, *i.e.,* a dataframe with the following columns: \n",
    "**Question**: How many rows do you expect the dataframe to have?\n",
    "```\n",
    "['index_x', 'culmen_length_mm_x', 'culmen_depth_mm_x',\n",
    "'flipper_length_mm_x', 'body_mass_g_x', 'index_y', 'culmen_length_mm_y',\n",
    "'culmen_depth_mm_y', 'flipper_length_mm_y', 'body_mass_g_y']\n",
    "```\n",
    "\n",
    "*Hint:* Check `pd.merge` with parameter `how = 'cross'` and use `.reset_index()` to keep the original indexes of the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Build a function that receives a row of the dataframe `all_comb` and outputs the two points you want to measure distance between. That is:\n",
    " - point A should have info about `'culmen_length_mm_x', 'culmen_depth_mm_x','flipper_length_mm_x', 'body_mass_g_x'`\n",
    " - point B should have info about `'culmen_length_mm_y', 'culmen_depth_mm_y','flipper_length_mm_y', 'body_mass_g_y'`\n",
    " \n",
    "*Hint:* Use `.to_numpy()` to turn a series into a numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Build 3 functions corresponding to 3 different distances: they should receive a row of `all_comb` and output the corresponding distance from the two point in a row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5. Create 3 new columns with the different distances between the points by `apply`ing your functions to the `all_comb` rows.\n",
    "Note: It can take some time to run - your doing a lot of calculations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting a point's neighbors \n",
    "#### 2.1 Get the 5 closest points to the penguin with original `index_x = 10` (using a distance of your choice).\n",
    "*Note:* the closest point will always be the point itself with a distance of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Using the indexes from the obtained points, check the original dataframe (with categorical features) to see if there is a pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. If you didn't know the species and gender of your penguin, based on its neighbours what would be your guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. ü§î  Look at the numerical variables' scale. What feature do you think is impacting the distance the most? Should this be the case? What can we do to prevent this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (OPTIONAL) 2.5. Repeat the same exercise with different distances of your choice and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Let's use Sklearn to predict a penguin's gender with the KNN model.\n",
    "**Steps** \n",
    " 1. Import [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) model from Sklearn. \n",
    " \n",
    " 2. Create a dataframe `X` with the numerical features and a series `y` with the target (`is_male`)\n",
    " 3. Instantiate the model `knn = KNeighborsClassifier()`\n",
    " 4. Fit it on your data.\n",
    " 5. Check what parameters `n_neighbors` and `metric` are in the documentation. What values are being used by default?\n",
    " 6. Import classification metrics of your choice from sklearn.\n",
    " 7. Use your trained model to make predictions for your dataset.\n",
    " 8. Measure your model's performance with your classification metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing different models\n",
    "\n",
    "**Steps:**\n",
    " 1. Load the test data below\n",
    " \n",
    " 2. Create variables `X_test` and `y_test`, similarly as you did before\n",
    " 3. Define different `KNeighborsClassifier` models by choosing different values for `n_neighbors` and `metric` (see available distances [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics)). You should use at least 4 models: 5 and 10 neighbors with Euclidean and Manhattan distances. (Feel free to test as many as you want)\n",
    " 4. Use the provided function `get_metrics` to compare the different models.\n",
    " 5. Which parameters yields a better peformance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The importance of scaling\n",
    "\n",
    "**Steps:**\n",
    " 1. Import [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) from Sklearn\n",
    " \n",
    " 2. Instantiate (`scaler = StandardScaler()`) and fit your scaler on your training data\n",
    " 3. Create two new datasets `X_train_scaled` and `X_test_scaled` by using your scaler to `transform` your training and test data\n",
    "**üö® You should ONLY fit your scaler on the training data. Test data is unseen data which we know nothing about at the moment of training, it will be scaled with the information we get from the training data**\n",
    " 4. Re-run your `get_metrics` function with the same models as before bu using the scaled versions of your data: `X_train_scaled` and `X_test_scaled`.\n",
    " 5. Contemplate the importance of scaling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clustering with KMeans\n",
    "\n",
    "**Steps:**\n",
    " 1. Import [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) from Sklearn.\n",
    " 2. Create a **for** loop that for each value of **k** between 1 and 10: \n",
    "  1. Defines `model = KMeans()` with parameter **k**\n",
    "  2. Fits model on `X_train_scaled`\n",
    "  3. Saves model's inertia (`model.inertia_`) in a list\n",
    " \n",
    " 3. Plot the values of inertia against values of k \n",
    " 4. Identify the elbow in the curve\n",
    " 5. Define and fit a KMeans with `n_clusters = 3` on `X_train_scaled`\n",
    " 6. Use your model to make predicitions on `X_train_scaled`, store the predictions on a variable named `clusters_3`\n",
    " 7. Run the following command `plt.scatter(X.culmen_depth_mm,X.culmen_length_mm, c = clusters_3)`, plotting the original's data culmen_depth_mm vs. culmen_length_mm, with each point colored according to the cluster it belongs to. \n",
    " 8. What do you think the clusters could represent? Check your original dataframe's categorical features. \n",
    " 9. Use `pd.crosstab` to compare `clusters_3` with the `island` and `species` features. Which variable do the clusters seem to be representing?\n",
    "\n",
    "**(OPTIONAL)** Repeat 5 - 8 with `n_clusters = 2` and compare predictions with the `is_male` variable. \n",
    "\n",
    "**‚ö†Ô∏è Remember:** Clustering is a type of Unsupervised Learning - there is **no target**. It is up to us to interpret what each cluster can represent and analyse each cluster in order to draw conclusions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
